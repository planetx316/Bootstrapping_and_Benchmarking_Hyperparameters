{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bootstrapping and Benchmarking Hyperparameters.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ig08UPe0Etcz"
      },
      "source": [
        "Quite a few hyperparameters have been introduced so far. Tweaking each of these values can have an effect on the score obtained by your neural networks. Some of the hyperparameters seen so far include:\n",
        "\n",
        "  - Number of layers in the neural network\n",
        "  - How many neurons in each layer\n",
        "  - What activation functions to use on each layer\n",
        "  - Dropout percent on each layer\n",
        "  - L1 and L2 values on each layer\n",
        "\n",
        "To try out each of these hyperparameters you will need to run train neural networks with multiple settings for each hyperparameter. However, you may have noticed that neural networks often produce somewhat different results when trained multiple times. This is because the neural networks start with random weights. Because of this it is necessary to fit and evaluate a neural network times to ensure that one set of hyperparameters are actually better than another. Bootstrapping can be an effective means of benchmarking (comparing) two sets of hyperparameters.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSsUvkkVEhPk"
      },
      "source": [
        "import pandas as pd\n",
        "from scipy.stats import zscore\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Read the data set\n",
        "df = pd.read_csv(\n",
        "    \"https://data.heatonresearch.com/data/t81-558/jh-simple-dataset.csv\",\n",
        "    na_values=['NA','?'])\n",
        "\n",
        "# Generate dummies for job\n",
        "df = pd.concat([df,pd.get_dummies(df['job'],prefix=\"job\")],axis=1)\n",
        "df.drop('job', axis=1, inplace=True)\n",
        "\n",
        "# Generate dummies for area\n",
        "df = pd.concat([df,pd.get_dummies(df['area'],prefix=\"area\")],axis=1)\n",
        "df.drop('area', axis=1, inplace=True)\n",
        "\n",
        "# Generate dummies for product\n",
        "df = pd.concat([df,pd.get_dummies(df['product'],prefix=\"product\")],axis=1)\n",
        "df.drop('product', axis=1, inplace=True)\n",
        "\n",
        "# Missing values for income\n",
        "med = df['income'].median()\n",
        "df['income'] = df['income'].fillna(med)\n",
        "\n",
        "# Standardize ranges\n",
        "df['income'] = zscore(df['income'])\n",
        "df['aspect'] = zscore(df['aspect'])\n",
        "df['save_rate'] = zscore(df['save_rate'])\n",
        "df['subscriptions'] = zscore(df['subscriptions'])\n",
        "\n",
        "# Convert to numpy - Classification\n",
        "x_columns = df.columns.drop('age').drop('id')\n",
        "x = df[x_columns].values\n",
        "y = df['age'].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dyfj4vCTFJrx"
      },
      "source": [
        "# Bootstrapping\n",
        "This will help us in optimizing hyperparameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Og126DSEFHEI"
      },
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "import time\n",
        "import statistics\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.model_selection import ShuffleSplit\n",
        "# Because we are benchmarking, we will display the amount of time taken for each cycle. \n",
        "# The following function can be used to nicely format a time span.Nicely formatted time string\n",
        "def hms_string(sec_elapsed):\n",
        "    h = int(sec_elapsed / (60 * 60))\n",
        "    m = int((sec_elapsed % (60 * 60)) / 60)\n",
        "    s = sec_elapsed % 60\n",
        "    return \"{}:{:>02}:{:>05.2f}\".format(h, m, s)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "1eBGItkuFk-m",
        "outputId": "bdb89ea5-8490-4804-8c27-35d1d214fcbd"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "SPLITS = 50\n",
        "\n",
        "# Bootstrap\n",
        "boot = ShuffleSplit(n_splits=SPLITS, test_size=0.1, random_state=42)\n",
        "\n",
        "# Track progress\n",
        "mean_benchmark = []\n",
        "epochs_needed = []\n",
        "num = 0\n",
        "\n",
        "# Loop through samples\n",
        "for train, test in boot.split(x):\n",
        "    start_time = time.time()\n",
        "    num+=1\n",
        "\n",
        "    # Split train and test\n",
        "    x_train = x[train]\n",
        "    y_train = y[train]\n",
        "    x_test = x[test]\n",
        "    y_test = y[test]\n",
        "\n",
        "    # Construct neural network\n",
        "    model = Sequential()\n",
        "    model.add(Dense(20, input_dim=x_train.shape[1], activation='relu'))\n",
        "    model.add(Dense(10, activation='relu'))\n",
        "    model.add(Dense(1))\n",
        "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "    \n",
        "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, \n",
        "        patience=5, verbose=0, mode='auto', restore_best_weights=True)\n",
        "\n",
        "    # Train on the bootstrap sample\n",
        "    model.fit(x_train,y_train,validation_data=(x_test,y_test),\n",
        "              callbacks=[monitor],verbose=0,epochs=1000)\n",
        "    epochs = monitor.stopped_epoch\n",
        "    epochs_needed.append(epochs)\n",
        "    \n",
        "    # Predict on the out of boot (validation)\n",
        "    pred = model.predict(x_test)\n",
        "  \n",
        "    # Measure this bootstrap's log loss\n",
        "    score = np.sqrt(metrics.mean_squared_error(pred,y_test))\n",
        "    mean_benchmark.append(score)\n",
        "    m1 = statistics.mean(mean_benchmark)\n",
        "    m2 = statistics.mean(epochs_needed)\n",
        "    mdev = statistics.pstdev(mean_benchmark)\n",
        "    \n",
        "    # Record this iteration\n",
        "    time_took = time.time() - start_time\n",
        "    print(f\"#{num}: score={score:.6f}, mean score={m1:.6f}, stdev={mdev:.6f},epochs={epochs}, mean epochs={int(m2)},time={hms_string(time_took)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-77d5a1babdee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;31m# Measure this bootstrap's log loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m     \u001b[0mmean_benchmark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mm1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstatistics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_benchmark\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_regression.py\u001b[0m in \u001b[0;36mmean_squared_error\u001b[0;34m(y_true, y_pred, sample_weight, multioutput, squared)\u001b[0m\n\u001b[1;32m    250\u001b[0m     \"\"\"\n\u001b[1;32m    251\u001b[0m     y_type, y_true, y_pred, multioutput = _check_reg_targets(\n\u001b[0;32m--> 252\u001b[0;31m         y_true, y_pred, multioutput)\n\u001b[0m\u001b[1;32m    253\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m     output_errors = np.average((y_true - y_pred) ** 2, axis=0,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_regression.py\u001b[0m in \u001b[0;36m_check_reg_targets\u001b[0;34m(y_true, y_pred, multioutput, dtype)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         raise ValueError(\"y_true and y_pred have different number of output \"\n\u001b[0;32m---> 96\u001b[0;31m                          \"({0}!={1})\".format(y_true.shape[1], y_pred.shape[1]))\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0mn_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: y_true and y_pred have different number of output (1!=7)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stNxo1oDWnAg"
      },
      "source": [
        "You can see that the mean epochs has converged to 115, which shows that this is the number of epochs our model needs to be trained on. Now let's use a Stratified shuffle split\n",
        "\n",
        "\n",
        "#Stratified Shuffle split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YuV1_2tRHC_i",
        "outputId": "cd78de43-baf5-4caf-dd76-b88c7eb15766"
      },
      "source": [
        "import pandas as pd\n",
        "from scipy.stats import zscore\n",
        "\n",
        "# Read the data set\n",
        "df = pd.read_csv(\n",
        "    \"https://data.heatonresearch.com/data/t81-558/jh-simple-dataset.csv\",\n",
        "    na_values=['NA','?'])\n",
        "\n",
        "# Generate dummies for job\n",
        "df = pd.concat([df,pd.get_dummies(df['job'],prefix=\"job\")],axis=1)\n",
        "df.drop('job', axis=1, inplace=True)\n",
        "\n",
        "# Generate dummies for area\n",
        "df = pd.concat([df,pd.get_dummies(df['area'],prefix=\"area\")],axis=1)\n",
        "df.drop('area', axis=1, inplace=True)\n",
        "\n",
        "# Missing values for income\n",
        "med = df['income'].median()\n",
        "df['income'] = df['income'].fillna(med)\n",
        "\n",
        "# Standardize ranges\n",
        "df['income'] = zscore(df['income'])\n",
        "df['aspect'] = zscore(df['aspect'])\n",
        "df['save_rate'] = zscore(df['save_rate'])\n",
        "df['age'] = zscore(df['age'])\n",
        "df['subscriptions'] = zscore(df['subscriptions'])\n",
        "\n",
        "# Convert to numpy - Classification\n",
        "x_columns = df.columns.drop('product').drop('id')\n",
        "x = df[x_columns].values\n",
        "dummies = pd.get_dummies(df['product']) # Classification\n",
        "products = dummies.columns\n",
        "y = dummies.values\n",
        "\n",
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "import time\n",
        "import statistics\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "SPLITS = 50\n",
        "\n",
        "# Bootstrap\n",
        "boot = StratifiedShuffleSplit(n_splits=SPLITS, test_size=0.1, \n",
        "                                random_state=42)\n",
        "\n",
        "# Track progress\n",
        "mean_benchmark = []\n",
        "epochs_needed = []\n",
        "num = 0\n",
        "\n",
        "# Loop through samples\n",
        "for train, test in boot.split(x,df['product']):\n",
        "    start_time = time.time()\n",
        "    num+=1\n",
        "\n",
        "    # Split train and test\n",
        "    x_train = x[train]\n",
        "    y_train = y[train]\n",
        "    x_test = x[test]\n",
        "    y_test = y[test]\n",
        "\n",
        "    # Construct neural network\n",
        "    model = Sequential()\n",
        "    model.add(Dense(50, input_dim=x.shape[1], activation='relu')) # Hidden 1\n",
        "    model.add(Dense(25, activation='relu')) # Hidden 2\n",
        "    model.add(Dense(y.shape[1],activation='softmax')) # Output\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, \n",
        "        patience=25, verbose=0, mode='auto', restore_best_weights=True)\n",
        "\n",
        "    # Train on the bootstrap sample\n",
        "    model.fit(x_train,y_train,validation_data=(x_test,y_test),\n",
        "              callbacks=[monitor],verbose=0,epochs=1000)\n",
        "    epochs = monitor.stopped_epoch\n",
        "    epochs_needed.append(epochs)\n",
        "    \n",
        "    # Predict on the out of boot (validation)\n",
        "    pred = model.predict(x_test)\n",
        "  \n",
        "    # Measure this bootstrap's log loss\n",
        "    y_compare = np.argmax(y_test,axis=1) # For log loss calculation\n",
        "    score = metrics.log_loss(y_compare, pred)\n",
        "    mean_benchmark.append(score)\n",
        "    m1 = statistics.mean(mean_benchmark)\n",
        "    m2 = statistics.mean(epochs_needed)\n",
        "    mdev = statistics.pstdev(mean_benchmark)\n",
        "    \n",
        "    # Record this iteration\n",
        "    time_took = time.time() - start_time\n",
        "    print(f\"#{num}: score={score:.6f}, mean score={m1:.6f},\" +\\\n",
        "          f\"stdev={mdev:.6f}, epochs={epochs}, mean epochs={int(m2)},\" +\\\n",
        "          f\" time={hms_string(time_took)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "#1: score=0.672750, mean score=0.672750,stdev=0.000000, epochs=65, mean epochs=65, time=0:00:06.46\n",
            "#2: score=0.682508, mean score=0.677629,stdev=0.004879, epochs=59, mean epochs=62, time=0:00:05.96\n",
            "#3: score=0.683138, mean score=0.679465,stdev=0.004756, epochs=49, mean epochs=57, time=0:00:05.20\n",
            "#4: score=0.669935, mean score=0.677083,stdev=0.005830, epochs=79, mean epochs=63, time=0:00:07.77\n",
            "#5: score=0.664958, mean score=0.674658,stdev=0.007122, epochs=88, mean epochs=68, time=0:00:08.49\n",
            "#6: score=0.707374, mean score=0.680110,stdev=0.013818, epochs=58, mean epochs=66, time=0:00:05.81\n",
            "#7: score=0.709035, mean score=0.684243,stdev=0.016312, epochs=58, mean epochs=65, time=0:00:05.98\n",
            "#8: score=0.729450, mean score=0.689893,stdev=0.021363, epochs=43, mean epochs=62, time=0:00:04.48\n",
            "#9: score=0.639409, mean score=0.684284,stdev=0.025639, epochs=61, mean epochs=62, time=0:00:06.14\n",
            "#10: score=0.656716, mean score=0.681527,stdev=0.025691, epochs=99, mean epochs=65, time=0:00:09.57\n",
            "#11: score=0.690297, mean score=0.682325,stdev=0.024625, epochs=71, mean epochs=66, time=0:00:07.13\n",
            "#12: score=0.725743, mean score=0.685943,stdev=0.026455, epochs=55, mean epochs=65, time=0:00:05.57\n",
            "#13: score=0.717181, mean score=0.688346,stdev=0.026745, epochs=71, mean epochs=65, time=0:00:07.05\n",
            "#14: score=0.725682, mean score=0.691013,stdev=0.027508, epochs=58, mean epochs=65, time=0:00:05.98\n",
            "#15: score=0.616669, mean score=0.686056,stdev=0.032406, epochs=67, mean epochs=65, time=0:00:06.55\n",
            "#16: score=0.745720, mean score=0.689785,stdev=0.034541, epochs=48, mean epochs=64, time=0:00:04.92\n",
            "#17: score=0.652660, mean score=0.687601,stdev=0.034630, epochs=69, mean epochs=64, time=0:00:06.91\n",
            "#18: score=0.660139, mean score=0.686076,stdev=0.034237, epochs=58, mean epochs=64, time=0:00:05.73\n",
            "#19: score=0.603236, mean score=0.681716,stdev=0.038114, epochs=53, mean epochs=63, time=0:00:05.51\n",
            "#20: score=0.709133, mean score=0.683087,stdev=0.037626, epochs=60, mean epochs=63, time=0:00:05.86\n",
            "#21: score=0.654052, mean score=0.681704,stdev=0.037236, epochs=70, mean epochs=63, time=0:00:06.85\n",
            "#22: score=0.735076, mean score=0.684130,stdev=0.038041, epochs=61, mean epochs=63, time=0:00:06.17\n",
            "#23: score=0.623667, mean score=0.681501,stdev=0.039195, epochs=58, mean epochs=63, time=0:00:05.80\n",
            "#24: score=0.702550, mean score=0.682378,stdev=0.038599, epochs=78, mean epochs=64, time=0:00:07.57\n",
            "#25: score=0.561440, mean score=0.677541,stdev=0.044631, epochs=67, mean epochs=64, time=0:00:06.54\n",
            "#26: score=0.658934, mean score=0.676825,stdev=0.043911, epochs=59, mean epochs=63, time=0:00:05.85\n",
            "#27: score=0.693140, mean score=0.677429,stdev=0.043200, epochs=72, mean epochs=64, time=0:00:06.92\n",
            "#28: score=0.709949, mean score=0.678591,stdev=0.042848, epochs=70, mean epochs=64, time=0:00:06.98\n",
            "#29: score=0.658221, mean score=0.677888,stdev=0.042267, epochs=53, mean epochs=64, time=0:00:05.51\n",
            "#30: score=0.736966, mean score=0.679858,stdev=0.042888, epochs=55, mean epochs=63, time=0:00:05.51\n",
            "#31: score=0.735849, mean score=0.681664,stdev=0.043335, epochs=49, mean epochs=63, time=0:00:05.05\n",
            "#32: score=0.672235, mean score=0.681369,stdev=0.042684, epochs=76, mean epochs=63, time=0:00:07.60\n",
            "#33: score=0.628162, mean score=0.679757,stdev=0.043011, epochs=59, mean epochs=63, time=0:00:05.94\n",
            "#34: score=0.599905, mean score=0.677408,stdev=0.044470, epochs=74, mean epochs=63, time=0:00:07.30\n",
            "#35: score=0.500601, mean score=0.672357,stdev=0.052808, epochs=102, mean epochs=64, time=0:00:09.88\n",
            "#36: score=0.645390, mean score=0.671607,stdev=0.052258, epochs=50, mean epochs=64, time=0:00:05.01\n",
            "#37: score=0.646089, mean score=0.670918,stdev=0.051712, epochs=60, mean epochs=64, time=0:00:05.92\n",
            "#38: score=0.720404, mean score=0.672220,stdev=0.051639, epochs=67, mean epochs=64, time=0:00:06.83\n",
            "#39: score=0.712082, mean score=0.673242,stdev=0.051360, epochs=70, mean epochs=64, time=0:00:06.82\n",
            "#40: score=0.674913, mean score=0.673284,stdev=0.050715, epochs=41, mean epochs=64, time=0:00:04.36\n",
            "#41: score=0.737353, mean score=0.674847,stdev=0.051058, epochs=53, mean epochs=63, time=0:00:05.44\n",
            "#42: score=0.642531, mean score=0.674077,stdev=0.050687, epochs=71, mean epochs=63, time=0:00:07.20\n",
            "#43: score=0.690757, mean score=0.674465,stdev=0.050157, epochs=47, mean epochs=63, time=0:00:04.95\n",
            "#44: score=0.752342, mean score=0.676235,stdev=0.050924, epochs=50, mean epochs=63, time=0:00:05.12\n",
            "#45: score=0.649634, mean score=0.675644,stdev=0.050507, epochs=78, mean epochs=63, time=0:00:07.65\n",
            "#46: score=0.642146, mean score=0.674916,stdev=0.050194, epochs=55, mean epochs=63, time=0:00:05.54\n",
            "#47: score=0.697787, mean score=0.675402,stdev=0.049766, epochs=56, mean epochs=63, time=0:00:05.59\n",
            "#48: score=0.743938, mean score=0.676830,stdev=0.050209, epochs=64, mean epochs=63, time=0:00:06.68\n",
            "#49: score=0.671161, mean score=0.676714,stdev=0.049700, epochs=67, mean epochs=63, time=0:00:06.86\n",
            "#50: score=0.671948, mean score=0.676619,stdev=0.049205, epochs=46, mean epochs=62, time=0:00:04.82\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EwiPFMCBYUIQ"
      },
      "source": [
        "# Benchmarking\n",
        "Now with the above information we will try to benchmark and optimize the hyperparameters for the jh-simple-dataset data. So let's do a regression problem and predict the age.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jIVUpiCBXFB_"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.stats import zscore\n",
        "\n",
        "# Read the dataset\n",
        "df=pd.read_csv(\"https://data.heatonresearch.com/data/t81-558/jh-simple-dataset.csv\",\n",
        "    na_values=['NA','?'])\n",
        "\n",
        "# Generate dummies for job\n",
        "df = pd.concat([df,pd.get_dummies(df['job'],prefix=\"job\")],axis=1)\n",
        "df.drop('job', axis=1, inplace=True)\n",
        "\n",
        "# Generate dummies for area\n",
        "df = pd.concat([df,pd.get_dummies(df['area'],prefix=\"area\")],\n",
        "               axis=1)\n",
        "df.drop('area', axis=1, inplace=True)\n",
        "\n",
        "# Missing values for income\n",
        "med = df['income'].median()\n",
        "df['income'] = df['income'].fillna(med)\n",
        "\n",
        "# Standardize ranges\n",
        "df['income'] = zscore(df['income'])\n",
        "df['aspect'] = zscore(df['aspect'])\n",
        "df['save_rate'] = zscore(df['save_rate'])\n",
        "df['age'] = zscore(df['age'])\n",
        "df['subscriptions'] = zscore(df['subscriptions'])\n",
        "\n",
        "# Convert to numpy - Classification\n",
        "x_columns = df.columns.drop('product').drop('id')\n",
        "x = df[x_columns].values\n",
        "dummies = pd.get_dummies(df['product']) # Classification\n",
        "products = dummies.columns\n",
        "y = dummies.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j6ClBtiLZE2p",
        "outputId": "ec8c0f5f-bb07-4449-a0bb-90dd01804efe"
      },
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "import time\n",
        "import tensorflow.keras.initializers\n",
        "import statistics\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "from tensorflow.keras.layers import LeakyReLU,PReLU\n",
        "\n",
        "SPLITS = 100\n",
        "\n",
        "# Bootstrap\n",
        "boot = StratifiedShuffleSplit(n_splits=SPLITS, test_size=0.1)\n",
        "\n",
        "# Track progress\n",
        "mean_benchmark = []\n",
        "epochs_needed = []\n",
        "num = 0\n",
        "\n",
        "# Loop through samples\n",
        "for train, test in boot.split(x,df['product']):\n",
        "    start_time = time.time()\n",
        "    num+=1\n",
        "\n",
        "    # Split train and test\n",
        "    x_train = x[train]\n",
        "    y_train = y[train]\n",
        "    x_test = x[test]\n",
        "    y_test = y[test]\n",
        "\n",
        "    # Construct neural network\n",
        "    model = Sequential()\n",
        "    model.add(Dense(100, input_dim=x.shape[1], activation=PReLU(), \\\n",
        "        kernel_regularizer=regularizers.l2(1e-4))) # Hidden 1\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(100, activation=PReLU(), \\\n",
        "        activity_regularizer=regularizers.l2(1e-4))) # Hidden 2\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(100, activation=PReLU(), \\\n",
        "        activity_regularizer=regularizers.l2(1e-4)\n",
        "    )) # Hidden 3\n",
        "#    model.add(Dropout(0.5)) - Usually better performance \n",
        "# without dropout on final layer\n",
        "    model.add(Dense(y.shape[1],activation='softmax')) # Output\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, \n",
        "        patience=100, verbose=0, mode='auto', restore_best_weights=True)\n",
        "\n",
        "    # Train on the bootstrap sample\n",
        "    model.fit(x_train,y_train,validation_data=(x_test,y_test), \\\n",
        "              callbacks=[monitor],verbose=0,epochs=1000)\n",
        "    epochs = monitor.stopped_epoch\n",
        "    epochs_needed.append(epochs)\n",
        "    \n",
        "    # Predict on the out of boot (validation)\n",
        "    pred = model.predict(x_test)\n",
        "  \n",
        "    # Measure this bootstrap's log loss\n",
        "    y_compare = np.argmax(y_test,axis=1) # For log loss calculation\n",
        "    score = metrics.log_loss(y_compare, pred)\n",
        "    mean_benchmark.append(score)\n",
        "    m1 = statistics.mean(mean_benchmark)\n",
        "    m2 = statistics.mean(epochs_needed)\n",
        "    mdev = statistics.pstdev(mean_benchmark)\n",
        "    \n",
        "    # Record this iteration\n",
        "    time_took = time.time() - start_time\n",
        "    print(f\"#{num}: score={score:.6f}, mean score={m1:.6f},stdev={mdev:.6f}, epochs={epochs},mean epochs={int(m2)}, time={hms_string(time_took)}\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "#1: score=0.691219, mean score=0.691219,stdev=0.000000, epochs=165,mean epochs=165, time=0:00:24.21\n",
            "#2: score=0.631811, mean score=0.661515,stdev=0.029704, epochs=198,mean epochs=181, time=0:00:28.88\n",
            "#3: score=0.659198, mean score=0.660743,stdev=0.024278, epochs=194,mean epochs=185, time=0:00:28.16\n",
            "#4: score=0.706891, mean score=0.672280,stdev=0.029007, epochs=180,mean epochs=184, time=0:00:26.26\n",
            "#5: score=0.670784, mean score=0.671981,stdev=0.025951, epochs=238,mean epochs=195, time=0:00:34.35\n",
            "#6: score=0.690541, mean score=0.675074,stdev=0.024679, epochs=182,mean epochs=192, time=0:00:26.88\n",
            "#7: score=0.690681, mean score=0.677304,stdev=0.023492, epochs=164,mean epochs=188, time=0:00:23.97\n",
            "#8: score=0.700076, mean score=0.680150,stdev=0.023230, epochs=127,mean epochs=181, time=0:00:18.72\n",
            "#9: score=0.671658, mean score=0.679207,stdev=0.022063, epochs=151,mean epochs=177, time=0:00:22.06\n",
            "#10: score=0.658299, mean score=0.677116,stdev=0.021850, epochs=227,mean epochs=182, time=0:00:32.79\n",
            "#11: score=0.755054, mean score=0.684201,stdev=0.030595, epochs=188,mean epochs=183, time=0:00:27.40\n",
            "#12: score=0.641003, mean score=0.680601,stdev=0.031632, epochs=285,mean epochs=191, time=0:00:40.60\n",
            "#13: score=0.627146, mean score=0.676490,stdev=0.033564, epochs=262,mean epochs=197, time=0:00:38.43\n",
            "#14: score=0.703965, mean score=0.678452,stdev=0.033108, epochs=153,mean epochs=193, time=0:00:23.17\n",
            "#15: score=0.701314, mean score=0.679976,stdev=0.032490, epochs=153,mean epochs=191, time=0:00:23.32\n",
            "#16: score=0.613681, mean score=0.675833,stdev=0.035315, epochs=184,mean epochs=190, time=0:00:27.33\n",
            "#17: score=0.624684, mean score=0.672824,stdev=0.036313, epochs=152,mean epochs=188, time=0:00:23.50\n",
            "#18: score=0.696428, mean score=0.674135,stdev=0.035701, epochs=171,mean epochs=187, time=0:00:26.19\n",
            "#19: score=0.561495, mean score=0.668207,stdev=0.042897, epochs=270,mean epochs=191, time=0:00:40.83\n",
            "#20: score=0.692124, mean score=0.669403,stdev=0.042134, epochs=209,mean epochs=192, time=0:00:32.36\n",
            "#21: score=0.624618, mean score=0.667270,stdev=0.042210, epochs=273,mean epochs=196, time=0:00:41.95\n",
            "#22: score=0.672414, mean score=0.667504,stdev=0.041254, epochs=202,mean epochs=196, time=0:00:31.32\n",
            "#23: score=0.676324, mean score=0.667887,stdev=0.040387, epochs=255,mean epochs=199, time=0:00:38.24\n",
            "#24: score=0.714519, mean score=0.669830,stdev=0.040620, epochs=159,mean epochs=197, time=0:00:24.19\n",
            "#25: score=0.703209, mean score=0.671165,stdev=0.040333, epochs=161,mean epochs=196, time=0:00:24.96\n",
            "#26: score=0.641626, mean score=0.670029,stdev=0.039956, epochs=194,mean epochs=196, time=0:00:28.70\n",
            "#27: score=0.697577, mean score=0.671050,stdev=0.039553, epochs=185,mean epochs=195, time=0:00:27.73\n",
            "#28: score=0.717212, mean score=0.672698,stdev=0.039773, epochs=142,mean epochs=193, time=0:00:20.91\n",
            "#29: score=0.680983, mean score=0.672984,stdev=0.039111, epochs=168,mean epochs=192, time=0:00:24.92\n",
            "#30: score=0.641358, mean score=0.671930,stdev=0.038870, epochs=137,mean epochs=190, time=0:00:20.76\n",
            "#31: score=0.675038, mean score=0.672030,stdev=0.038242, epochs=207,mean epochs=191, time=0:00:30.12\n",
            "#32: score=0.664528, mean score=0.671796,stdev=0.037663, epochs=223,mean epochs=192, time=0:00:32.72\n",
            "#33: score=0.580699, mean score=0.669035,stdev=0.040241, epochs=209,mean epochs=192, time=0:00:30.27\n",
            "#34: score=0.617578, mean score=0.667522,stdev=0.040587, epochs=162,mean epochs=192, time=0:00:23.74\n",
            "#35: score=0.656327, mean score=0.667202,stdev=0.040046, epochs=214,mean epochs=192, time=0:00:31.24\n",
            "#36: score=0.667862, mean score=0.667220,stdev=0.039486, epochs=185,mean epochs=192, time=0:00:26.93\n",
            "#37: score=0.629541, mean score=0.666202,stdev=0.039425, epochs=195,mean epochs=192, time=0:00:28.23\n",
            "#38: score=0.718429, mean score=0.667576,stdev=0.039791, epochs=143,mean epochs=191, time=0:00:21.18\n",
            "#39: score=0.680717, mean score=0.667913,stdev=0.039333, epochs=167,mean epochs=190, time=0:00:25.90\n",
            "#40: score=0.709940, mean score=0.668964,stdev=0.039388, epochs=158,mean epochs=189, time=0:00:23.54\n",
            "#41: score=0.550690, mean score=0.666079,stdev=0.042971, epochs=213,mean epochs=190, time=0:00:31.13\n",
            "#42: score=0.675163, mean score=0.666295,stdev=0.042478, epochs=152,mean epochs=189, time=0:00:22.42\n",
            "#43: score=0.705387, mean score=0.667204,stdev=0.042393, epochs=149,mean epochs=188, time=0:00:21.93\n",
            "#44: score=0.626072, mean score=0.666270,stdev=0.042355, epochs=213,mean epochs=189, time=0:00:31.42\n",
            "#45: score=0.618308, mean score=0.665204,stdev=0.042474, epochs=166,mean epochs=188, time=0:00:25.23\n",
            "#46: score=0.605307, mean score=0.663902,stdev=0.042908, epochs=223,mean epochs=189, time=0:00:32.29\n",
            "#47: score=0.616731, mean score=0.662898,stdev=0.042991, epochs=267,mean epochs=190, time=0:00:38.57\n",
            "#48: score=0.639515, mean score=0.662411,stdev=0.042672, epochs=172,mean epochs=190, time=0:00:25.11\n",
            "#49: score=0.627448, mean score=0.661697,stdev=0.042523, epochs=220,mean epochs=191, time=0:00:31.86\n",
            "#50: score=0.559345, mean score=0.659650,stdev=0.044467, epochs=221,mean epochs=191, time=0:00:32.72\n",
            "#51: score=0.622529, mean score=0.658922,stdev=0.044329, epochs=259,mean epochs=193, time=0:00:37.99\n",
            "#52: score=0.632243, mean score=0.658409,stdev=0.044053, epochs=228,mean epochs=193, time=0:00:33.15\n",
            "#53: score=0.654738, mean score=0.658340,stdev=0.043639, epochs=194,mean epochs=193, time=0:00:28.19\n",
            "#54: score=0.608714, mean score=0.657421,stdev=0.043747, epochs=192,mean epochs=193, time=0:00:28.26\n",
            "#55: score=0.659903, mean score=0.657466,stdev=0.043349, epochs=293,mean epochs=195, time=0:00:41.80\n",
            "#56: score=0.658567, mean score=0.657486,stdev=0.042961, epochs=230,mean epochs=196, time=0:00:32.72\n",
            "#57: score=0.695219, mean score=0.658148,stdev=0.042869, epochs=175,mean epochs=195, time=0:00:25.74\n",
            "#58: score=0.593806, mean score=0.657039,stdev=0.043316, epochs=292,mean epochs=197, time=0:00:41.76\n",
            "#59: score=0.584460, mean score=0.655808,stdev=0.043957, epochs=168,mean epochs=196, time=0:00:24.83\n",
            "#60: score=0.666788, mean score=0.655991,stdev=0.043612, epochs=144,mean epochs=196, time=0:00:21.02\n",
            "#61: score=0.713858, mean score=0.656940,stdev=0.043872, epochs=156,mean epochs=195, time=0:00:23.01\n",
            "#62: score=0.649025, mean score=0.656812,stdev=0.043529, epochs=181,mean epochs=195, time=0:00:26.29\n",
            "#63: score=0.680864, mean score=0.657194,stdev=0.043286, epochs=151,mean epochs=194, time=0:00:22.09\n",
            "#64: score=0.602471, mean score=0.656339,stdev=0.043480, epochs=244,mean epochs=195, time=0:00:34.76\n",
            "#65: score=0.661859, mean score=0.656424,stdev=0.043149, epochs=204,mean epochs=195, time=0:00:29.27\n",
            "#66: score=0.631818, mean score=0.656051,stdev=0.042926, epochs=194,mean epochs=195, time=0:00:27.95\n",
            "#67: score=0.644558, mean score=0.655880,stdev=0.042628, epochs=179,mean epochs=195, time=0:00:25.60\n",
            "#68: score=0.581625, mean score=0.654788,stdev=0.043247, epochs=264,mean epochs=196, time=0:00:37.61\n",
            "#69: score=0.607218, mean score=0.654098,stdev=0.043307, epochs=192,mean epochs=196, time=0:00:27.51\n",
            "#70: score=0.675194, mean score=0.654400,stdev=0.043069, epochs=158,mean epochs=195, time=0:00:22.89\n",
            "#71: score=0.588887, mean score=0.653477,stdev=0.043456, epochs=213,mean epochs=195, time=0:00:30.43\n",
            "#72: score=0.619295, mean score=0.653002,stdev=0.043339, epochs=323,mean epochs=197, time=0:00:45.26\n",
            "#73: score=0.579804, mean score=0.651999,stdev=0.043874, epochs=184,mean epochs=197, time=0:00:26.55\n",
            "#74: score=0.742992, mean score=0.653229,stdev=0.044825, epochs=151,mean epochs=196, time=0:00:21.96\n",
            "#75: score=0.681228, mean score=0.653602,stdev=0.044641, epochs=152,mean epochs=196, time=0:00:22.06\n",
            "#76: score=0.681606, mean score=0.653971,stdev=0.044461, epochs=180,mean epochs=195, time=0:00:26.19\n",
            "#77: score=0.749508, mean score=0.655212,stdev=0.045476, epochs=156,mean epochs=195, time=0:00:22.85\n",
            "#78: score=0.614146, mean score=0.654685,stdev=0.045419, epochs=255,mean epochs=196, time=0:00:36.22\n",
            "#79: score=0.637348, mean score=0.654466,stdev=0.045172, epochs=175,mean epochs=195, time=0:00:25.14\n",
            "#80: score=0.624176, mean score=0.654087,stdev=0.045015, epochs=185,mean epochs=195, time=0:00:26.47\n",
            "#81: score=0.679111, mean score=0.654396,stdev=0.044822, epochs=197,mean epochs=195, time=0:00:28.49\n",
            "#82: score=0.622696, mean score=0.654009,stdev=0.044683, epochs=166,mean epochs=195, time=0:00:24.49\n",
            "#83: score=0.587516, mean score=0.653208,stdev=0.045002, epochs=315,mean epochs=196, time=0:00:44.60\n",
            "#84: score=0.700437, mean score=0.653771,stdev=0.045025, epochs=188,mean epochs=196, time=0:00:27.50\n",
            "#85: score=0.624082, mean score=0.653421,stdev=0.044874, epochs=179,mean epochs=196, time=0:00:26.44\n",
            "#86: score=0.586424, mean score=0.652642,stdev=0.045187, epochs=205,mean epochs=196, time=0:00:30.22\n",
            "#87: score=0.668502, mean score=0.652825,stdev=0.044958, epochs=272,mean epochs=197, time=0:00:39.60\n",
            "#88: score=0.663546, mean score=0.652946,stdev=0.044716, epochs=144,mean epochs=196, time=0:00:21.37\n",
            "#89: score=0.578113, mean score=0.652106,stdev=0.045159, epochs=206,mean epochs=196, time=0:00:30.59\n",
            "#90: score=0.689213, mean score=0.652518,stdev=0.045075, epochs=265,mean epochs=197, time=0:00:38.80\n",
            "#91: score=0.613683, mean score=0.652091,stdev=0.045009, epochs=183,mean epochs=197, time=0:00:27.33\n",
            "#92: score=0.601607, mean score=0.651542,stdev=0.045069, epochs=295,mean epochs=198, time=0:00:43.12\n",
            "#93: score=0.694564, mean score=0.652005,stdev=0.045045, epochs=184,mean epochs=198, time=0:00:26.38\n",
            "#94: score=0.632774, mean score=0.651800,stdev=0.044848, epochs=184,mean epochs=198, time=0:00:26.49\n",
            "#95: score=0.630142, mean score=0.651572,stdev=0.044666, epochs=176,mean epochs=198, time=0:00:25.83\n",
            "#96: score=0.653374, mean score=0.651591,stdev=0.044434, epochs=165,mean epochs=197, time=0:00:23.96\n",
            "#97: score=0.600521, mean score=0.651065,stdev=0.044504, epochs=167,mean epochs=197, time=0:00:24.61\n",
            "#98: score=0.652995, mean score=0.651084,stdev=0.044277, epochs=194,mean epochs=197, time=0:00:28.56\n",
            "#99: score=0.704935, mean score=0.651628,stdev=0.044380, epochs=173,mean epochs=197, time=0:00:25.81\n",
            "#100: score=0.696488, mean score=0.652077,stdev=0.044383, epochs=167,mean epochs=196, time=0:00:24.81\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCi4VHiyaKGN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}